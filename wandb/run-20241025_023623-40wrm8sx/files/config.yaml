wandb_version: 1

learning_rate:
  desc: null
  value: 0.0001
architecture:
  desc: null
  value: Transformer With CNN advanced
dataset:
  desc: null
  value:
  - tap
  - slide
modelType:
  desc: null
  value: typeClassifier
model:
  desc: null
  value: "TransformerWithCNN_tapDetection(\n  (acc_cnn): Sequential(\n    (0): Conv1d(3,\
    \ 32, kernel_size=(5,), stride=(1,), padding=(2,))\n    (1): MaxPool1d(kernel_size=4,\
    \ stride=4, padding=0, dilation=1, ceil_mode=False)\n    (2): Conv1d(32, 64, kernel_size=(5,),\
    \ stride=(1,), padding=(2,))\n    (3): MaxPool1d(kernel_size=4, stride=4, padding=0,\
    \ dilation=1, ceil_mode=False)\n  )\n  (audio_cnn): Sequential(\n    (0): Conv1d(1,\
    \ 32, kernel_size=(5,), stride=(1,), padding=(2,))\n    (1): MaxPool1d(kernel_size=4,\
    \ stride=4, padding=0, dilation=1, ceil_mode=False)\n    (2): Conv1d(32, 64, kernel_size=(5,),\
    \ stride=(1,), padding=(2,))\n    (3): MaxPool1d(kernel_size=4, stride=4, padding=0,\
    \ dilation=1, ceil_mode=False)\n  )\n  (transformer_encoder_layer): TransformerEncoderLayer(\n\
    \    (self_attn): MultiheadAttention(\n      (out_proj): NonDynamicallyQuantizableLinear(in_features=128,\
    \ out_features=128, bias=True)\n    )\n    (linear1): Linear(in_features=128,\
    \ out_features=2048, bias=True)\n    (dropout): Dropout(p=0.1, inplace=False)\n\
    \    (linear2): Linear(in_features=2048, out_features=128, bias=True)\n    (norm1):\
    \ LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n    (norm2): LayerNorm((128,),\
    \ eps=1e-05, elementwise_affine=True)\n    (dropout1): Dropout(p=0.1, inplace=False)\n\
    \    (dropout2): Dropout(p=0.1, inplace=False)\n  )\n  (transformer_encoder):\
    \ TransformerEncoder(\n    (layers): ModuleList(\n      (0-1): 2 x TransformerEncoderLayer(\n\
    \        (self_attn): MultiheadAttention(\n          (out_proj): NonDynamicallyQuantizableLinear(in_features=128,\
    \ out_features=128, bias=True)\n        )\n        (linear1): Linear(in_features=128,\
    \ out_features=2048, bias=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n\
    \        (linear2): Linear(in_features=2048, out_features=128, bias=True)\n  \
    \      (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n      \
    \  (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n        (dropout1):\
    \ Dropout(p=0.1, inplace=False)\n        (dropout2): Dropout(p=0.1, inplace=False)\n\
    \      )\n    )\n  )\n  (fc): Linear(in_features=128, out_features=8, bias=True)\n\
    )"
epochs:
  desc: null
  value: 600
batchSize:
  desc: null
  value: 32
_wandb:
  desc: null
  value:
    python_version: 3.9.18
    cli_version: 0.17.0
    framework: torch
    is_jupyter_run: false
    is_kaggle_kernel: false
    start_time: 1729791383
    t:
      1:
      - 1
      - 5
      - 53
      - 55
      2:
      - 1
      - 5
      - 53
      - 55
      3:
      - 16
      - 23
      4: 3.9.18
      5: 0.17.0
      8:
      - 5
      13: darwin-x86_64
